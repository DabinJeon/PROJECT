{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체이미지 디렉터리 경로\n",
    "original_dataset_dir = 'all_image'\n",
    "# 분류해서 저장할 디렉터리 경로\n",
    "base_dir = 'all_images'\n",
    "os.mkdir(base_dir)\n",
    " \n",
    "# 훈련, 검증, 테스트 분할을 위한 디렉터리 생성\n",
    "# 새로운 모델 생성시 all_images 삭제할것\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "###############################################################\n",
    "# 훈련용 사과 사진 디렉터리\n",
    "train_apples_dir = os.path.join(train_dir, 'apples')\n",
    "os.mkdir(train_apples_dir)\n",
    " \n",
    "# 훈련용 태극기 사진 디렉터리\n",
    "train_taes_dir = os.path.join(train_dir, 'taes')\n",
    "os.mkdir(train_taes_dir)\n",
    "\n",
    "# 훈련용 모니터 사진 디렉터리\n",
    "train_monitors_dir = os.path.join(train_dir, 'monitors')\n",
    "os.mkdir(train_monitors_dir)\n",
    "\n",
    "# 훈련용 토끼 사진 디렉터리\n",
    "train_rabbits_dir = os.path.join(train_dir, 'rabbits')\n",
    "os.mkdir(train_rabbits_dir)\n",
    "\n",
    "# 훈련용 연필 사진 디렉터리\n",
    "train_pencils_dir = os.path.join(train_dir, 'pencils')\n",
    "os.mkdir(train_pencils_dir)\n",
    "\n",
    "# 훈련용 구름 사진 디렉터리\n",
    "train_clouds_dir = os.path.join(train_dir, 'clouds')\n",
    "os.mkdir(train_clouds_dir)\n",
    "\n",
    "# 훈련용 버스 사진 디렉터리\n",
    "train_buses_dir = os.path.join(train_dir, 'buses')\n",
    "os.mkdir(train_buses_dir)\n",
    "\n",
    "# 훈련용 해 사진 디렉터리\n",
    "train_suns_dir = os.path.join(train_dir, 'suns')\n",
    "os.mkdir(train_suns_dir)\n",
    "\n",
    "# 훈련용 바지 사진 디렉터리\n",
    "train_pants_dir = os.path.join(train_dir, 'pants')\n",
    "os.mkdir(train_pants_dir)\n",
    "\n",
    "# 훈련용 안경 사진 디렉터리\n",
    "train_glasses_dir = os.path.join(train_dir, 'glasses')\n",
    "os.mkdir(train_glasses_dir)\n",
    "###############################################################\n",
    "# 검증용 사과 사진 디렉터리\n",
    "validation_apples_dir = os.path.join(validation_dir, 'apples')\n",
    "os.mkdir(validation_apples_dir)\n",
    " \n",
    "# 검증용 태극기 사진 디렉터리\n",
    "validation_taes_dir = os.path.join(validation_dir, 'taes')\n",
    "os.mkdir(validation_taes_dir)\n",
    "\n",
    "# 검증용 모니터 사진 디렉터리\n",
    "validation_monitors_dir = os.path.join(validation_dir, 'monitors')\n",
    "os.mkdir(validation_monitors_dir)\n",
    "\n",
    "# 검증용 토끼 사진 디렉터리\n",
    "validation_rabbits_dir = os.path.join(validation_dir, 'rabbits')\n",
    "os.mkdir(validation_rabbits_dir)\n",
    "\n",
    "# 검증용 연필 사진 디렉터리\n",
    "validation_pencils_dir = os.path.join(validation_dir, 'pencils')\n",
    "os.mkdir(validation_pencils_dir)\n",
    "\n",
    "# 검증용 구름 사진 디렉터리\n",
    "validation_clouds_dir = os.path.join(validation_dir, 'clouds')\n",
    "os.mkdir(validation_clouds_dir)\n",
    "\n",
    "# 검증용 버스 사진 디렉터리\n",
    "validation_buses_dir = os.path.join(validation_dir, 'buses')\n",
    "os.mkdir(validation_buses_dir)\n",
    "\n",
    "# 검증용 해 사진 디렉터리\n",
    "validation_suns_dir = os.path.join(validation_dir, 'suns')\n",
    "os.mkdir(validation_suns_dir)\n",
    "\n",
    "# 검증용 바지 사진 디렉터리\n",
    "validation_pants_dir = os.path.join(validation_dir, 'pants')\n",
    "os.mkdir(validation_pants_dir)\n",
    "\n",
    "# 검증용 안경 사진 디렉터리\n",
    "validation_glasses_dir = os.path.join(validation_dir, 'glasses')\n",
    "os.mkdir(validation_glasses_dir)\n",
    "###############################################################\n",
    "# 테스트용 사과 사진 디렉터리\n",
    "test_apples_dir = os.path.join(test_dir, 'apples')\n",
    "os.mkdir(test_apples_dir)\n",
    " \n",
    "# 테스트용 태극기 사진 디렉터리\n",
    "test_taes_dir = os.path.join(test_dir, 'taes')\n",
    "os.mkdir(test_taes_dir)\n",
    "\n",
    "# 테스트용 모니터 사진 디렉터리\n",
    "test_monitors_dir = os.path.join(test_dir, 'monitors')\n",
    "os.mkdir(test_monitors_dir)\n",
    "\n",
    "# 테스트용 토끼 사진 디렉터리\n",
    "test_rabbits_dir = os.path.join(test_dir, 'rabbits')\n",
    "os.mkdir(test_rabbits_dir)\n",
    "\n",
    "# 테스트용 연필 사진 디렉터리\n",
    "test_pencils_dir = os.path.join(test_dir, 'pencils')\n",
    "os.mkdir(test_pencils_dir)\n",
    "\n",
    "# 테스트용 구름 사진 디렉터리\n",
    "test_clouds_dir = os.path.join(test_dir, 'clouds')\n",
    "os.mkdir(test_clouds_dir)\n",
    "\n",
    "# 테스트용 버스 사진 디렉터리\n",
    "test_buses_dir = os.path.join(test_dir, 'buses')\n",
    "os.mkdir(test_buses_dir)\n",
    "\n",
    "# 테스트용 해 사진 디렉터리\n",
    "test_suns_dir = os.path.join(test_dir, 'suns')\n",
    "os.mkdir(test_suns_dir)\n",
    "\n",
    "# 테스트용 바지 사진 디렉터리\n",
    "test_pants_dir = os.path.join(test_dir, 'pants')\n",
    "os.mkdir(test_pants_dir)\n",
    "\n",
    "# 테스트용 안경 사진 디렉터리\n",
    "test_glasses_dir = os.path.join(test_dir, 'glasses')\n",
    "os.mkdir(test_glasses_dir)\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음 60개의 사과 이미지를 train_apples_dir에 복사\n",
    "fnames = ['apple_{}.jpg'.format(i) for i in range(60)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_apples_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 다음 10개의 사과 이미지를 validation_apples_dir에 복사\n",
    "fnames = ['apple_{}.jpg'.format(i) for i in range(60, 70)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_apples_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 다음 10개의 사과 이미지를 test_apples_dir에 복사\n",
    "fnames = ['apple_{}.jpg'.format(i) for i in range(70, 80)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_apples_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "###############################################################\n",
    "\n",
    "# 처음 60개의 버스 이미지를 train_buses_dir에 복사\n",
    "fnames = ['buses_{}.jpg'.format(i) for i in range(60)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_buses_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "# 다음 20개의 버스 이미지를 validation_buses_dir에 복사\n",
    "fnames = ['buses_{}.jpg'.format(i) for i in range(60, 70)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_buses_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 다음 20개의 버스 이미지를 test_buses_dir에 복사\n",
    "fnames = ['buses_{}.jpg'.format(i) for i in range(70, 80)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_buses_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "###############################################################\n",
    "    \n",
    "# 처음 60개의 구름 이미지를 train_clouds_dir에 복사\n",
    "fnames = ['cloud_{}.jpg'.format(i) for i in range(60)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_clouds_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "# 다음 10개의 구름 이미지를 validation_clouds_dir에 복사\n",
    "fnames = ['cloud_{}.jpg'.format(i) for i in range(60, 70)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_clouds_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 다음 10개의 구름 이미지를 test_clouds_dir에 복사\n",
    "fnames = ['cloud_{}.jpg'.format(i) for i in range(70, 80)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_clouds_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "###############################################################\n",
    "\n",
    "# 처음 60개의 안경 이미지를 train_glasses_dir에 복사\n",
    "fnames = ['glasses_{}.jpg'.format(i) for i in range(60)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_glasses_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "# 다음 20개의 안경 이미지를 validation_glasses_dir에 복사\n",
    "fnames = ['glasses_{}.jpg'.format(i) for i in range(60, 70)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_glasses_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 다음 20개의 안경 이미지를 test_glasses_dir에 복사\n",
    "fnames = ['glasses_{}.jpg'.format(i) for i in range(70, 80)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_glasses_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "###############################################################\n",
    "\n",
    "# 처음 80개의 모니터 이미지를 train_monitors_dir에 복사\n",
    "fnames = ['monitor_{}.jpg'.format(i) for i in range(80)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_monitors_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "# 다음 10개의 모니터 이미지를 validation_monitors_dir에 복사\n",
    "fnames = ['monitor_{}.jpg'.format(i) for i in range(80, 90)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_monitors_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 다음 10개의 모니터 이미지를 test_monitors_dir에 복사\n",
    "fnames = ['monitor_{}.jpg'.format(i) for i in range(90, 100)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_monitors_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "###############################################################\n",
    "    \n",
    "# 처음 60개의 바지 이미지를 train_pants_dir에 복사\n",
    "fnames = ['pants_{}.jpg'.format(i) for i in range(60)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_pants_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "# 다음 20개의 바지 이미지를 validation_pants_dir에 복사\n",
    "fnames = ['pants_{}.jpg'.format(i) for i in range(60, 70)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_pants_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 다음 20개의 바지 이미지를 test_pants_dir에 복사\n",
    "fnames = ['pants_{}.jpg'.format(i) for i in range(70, 80)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_pants_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "###############################################################\n",
    "\n",
    "# 처음 60개의 연필 이미지를 train_pencils_dir에 복사\n",
    "fnames = ['pencil_{}.jpg'.format(i) for i in range(50)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_pencils_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "# 다음 20개의 연필 이미지를 validation_pencils_dir에 복사\n",
    "fnames = ['pencil_{}.jpg'.format(i) for i in range(50, 60)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_pencils_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 다음 20개의 연필 이미지를 test_pencils_dir에 복사\n",
    "fnames = ['pencil_{}.jpg'.format(i) for i in range(60, 70)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_pencils_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "###############################################################\n",
    "\n",
    "# 처음 41개의 토끼 이미지를 train_rabbits_dir에 복사\n",
    "fnames = ['rabbit_{}.jpg'.format(i) for i in range(41)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_rabbits_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "# 다음 10개의 토끼 이미지를 validation_rabbits_dir에 복사\n",
    "fnames = ['rabbit_{}.jpg'.format(i) for i in range(41, 51)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_rabbits_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 다음 10개의 토끼 이미지를 test_rabbits_dir에 복사\n",
    "fnames = ['rabbit_{}.jpg'.format(i) for i in range(51, 61)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_rabbits_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "###############################################################\n",
    "    \n",
    "# 처음 70개의 해 이미지를 train_suns_dir에 복사\n",
    "fnames = ['sun_{}.jpg'.format(i) for i in range(70)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_suns_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 다음 10개의 해 이미지를 validation_suns_dir에 복사\n",
    "fnames = ['sun_{}.jpg'.format(i) for i in range(70, 80)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_suns_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 다음 10개의 해 이미지를 test_suns_dir에 복사\n",
    "fnames = ['sun_{}.jpg'.format(i) for i in range(80,90)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_suns_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "###############################################################\n",
    "\n",
    "# 처음 60개의 태극기 이미지를 train_taes_dir에 복사\n",
    "fnames = ['tae_{}.jpg'.format(i) for i in range(60)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_taes_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "# 다음 10개의 태극기 이미지를 validation_taes_dir에 복사\n",
    "fnames = ['tae_{}.jpg'.format(i) for i in range(60, 70)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_taes_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 다음 10개의 태극기 이미지를 test_taes_dir에 복사\n",
    "fnames = ['tae_{}.jpg'.format(i) for i in range(70, 80)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_taes_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 사과 이미지 전체 개수 :  60\n",
      "검증용 사과 이미지 전체 개수 :  10\n",
      "테스트용 사과 이미지 전체 개수 :  10\n"
     ]
    }
   ],
   "source": [
    "# 복사가 잘 되었는지 확인하기 위해 (훈련/검증/테스트)에 들어있는 사진의 개수를 카운트\n",
    "print('훈련용 사과 이미지 전체 개수 : ', len(os.listdir(train_apples_dir)))\n",
    "print('검증용 사과 이미지 전체 개수 : ', len(os.listdir(validation_apples_dir)))\n",
    "print('테스트용 사과 이미지 전체 개수 : ', len(os.listdir(test_apples_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 601 images belonging to 10 classes.\n",
      "Found 100 images belonging to 10 classes.\n",
      "배치 데이터 크기 :  (10, 150, 150, 3)\n",
      "배치 레이블 크기 :  (10, 10)\n"
     ]
    }
   ],
   "source": [
    "# 모델의 훈련 설정하기\n",
    "\n",
    "from keras import optimizers\n",
    " \n",
    "# ImageDataGenerator를 사용하여 디렉터리에서 이미지를 읽어올수있음\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    " \n",
    "# 모든 이미지를 1/255 스케일로 조정\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# train 폴더에서 이미지 읽기\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, # 읽어올 디렉터리(훈련용)\n",
    "                                                    target_size = (150 ,150), # 모든 이미지를 150x150 크기로 바꿈\n",
    "                                                    batch_size = 10, # 몇개 이미지를 학습후 검증해볼것인가?\n",
    "                                                    class_mode = 'categorical') # 멀티클래스 분류\n",
    "\n",
    "# 검증 폴더에서 이미지 읽기\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir, \n",
    "                                                        target_size = (150, 150), \n",
    "                                                        batch_size = 10, \n",
    "                                                        class_mode = 'categorical')\n",
    " \n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('배치 데이터 크기 : ', data_batch.shape)\n",
    "    print('배치 레이블 크기 : ', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11301959521602148025\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1488230809\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16512626116608444907\n",
      "physical_device_desc: \"device: 0, name: GeForce GT 730, pci bus id: 0000:01:00.0, compute capability: 3.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.applications import VGG16 # VGG16, 사전정의된 네트워크활용\n",
    "                                     # 다른 네트워크 사용하고자 할 시\n",
    "                                     # import 변경하고 하단 conv_base의 함수도 변경할것\n",
    "\n",
    "# gpu활성 확인\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 사전정의 네트워크\n",
    "conv_base = VGG16(weights='imagenet', # 모델을 초기화할 가중치 체크포인트 지정\n",
    "                  include_top=False, # 네트워크의 최상위 완전 연결 분류기를 포함할것인가?\n",
    "                  input_shape=(150,150,3)) # 네트워크에 주입할 이미지 텐서의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Model)          (None, 4, 4, 1920)        18321984  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 30720)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               7864576   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 26,189,130\n",
      "Trainable params: 25,960,074\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model 클래스 -> 신경망의 훈련 과정을 구현\n",
    "# model클래스를 상속한 Sequential 클래스는 층(layer)뿐만 아니라 다른 모델도 추가가능\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='sigmoid')) # 10: 10가지를 분류하겠다\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱 기반층 동결\n",
    "# 훈련하는 동안 가중치가 업데이트가 되지않도록 막음\n",
    "# 동결하지 않으면 합성곱 기반층에 의해 사전 학습된 표현이 훈련하는동안 수정됨\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터 증식\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # 검증데이터는 증식x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 601 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# train 이미지 읽어오기\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(150,150),\n",
    "                                                    batch_size=10,\n",
    "                                                    class_mode='categorical')\n",
    "# class_mode = categorical -> 멀티클래스 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일 -> 변경사항을 적용\n",
    "model.compile(loss='categorical_crossentropy', # 멀티클래스 분류\n",
    "             optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 층까지 모든 층 동결\n",
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 미세조정\n",
    "# trainable 속성 변경시 모델을 다시 컴파일 해야함(변경사항적용)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-5), # 학습률을 낮춤 # 미세 조정하는 세개층에서 학습된 표현을 조금씩 수정하기 위함\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 126s 1s/step - loss: 1.9908 - acc: 0.3240 - val_loss: 1.5612 - val_acc: 0.6300\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 99s 994ms/step - loss: 1.2889 - acc: 0.6411 - val_loss: 0.9907 - val_acc: 0.7700\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 99s 994ms/step - loss: 0.8917 - acc: 0.7631 - val_loss: 0.9174 - val_acc: 0.8200\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 99s 989ms/step - loss: 0.6695 - acc: 0.8181 - val_loss: 0.7665 - val_acc: 0.8200\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 99s 992ms/step - loss: 0.5099 - acc: 0.8671 - val_loss: 0.7609 - val_acc: 0.8400\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=100,\n",
    "                              epochs=5, # 학습 반복횟수\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성한 모델 저장\n",
    "model.save('skm_classifier10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
